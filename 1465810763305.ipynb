{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy.stats as st\n",
    "import sklearn.metrics as met\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as prep\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "title = \"PPD\"\n",
    "path = \"C:/Users/recre/OneDrive/Stat\"\n",
    "icy = 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPD\n",
    "<script>alert('XSS!')</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Data\n",
    "\n",
    "Read data from orginal data files, save them into database which is easier to reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master Data\n",
    "Input:\n",
    "* Training Master Data:\n",
    "    * PPD_dat_1.csv: First-round training set of Master data\n",
    "    * PPD_dat_2.csv: First-round validation set of Master data\n",
    "    * PPD_dat_3.csv: Second-round training set of Master data\n",
    "    * PPD_dayt_2_1.csv: First-round public validation set of Y Labels\n",
    "    * PPD_dayt_2_2.csv: First-round private validation set of Y Labels\n",
    "* Validation Master Data:\n",
    "    * PPD_dav.csv: Second-round validation set of Master data\n",
    "    \n",
    "Output:\n",
    "* da: master data\n",
    "* irt, irv: sample indices of training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Read_concat_csv(file, par_csv = {}):\n",
    "    da = pd.concat(map(lambda x: pd.read_csv(x, **par_csv), file))\n",
    "    return(da)\n",
    "def Del_string(xstr):\n",
    "    xstrc = xstr.strip().strip(\"市\").strip(\"省\")\n",
    "    if(xstrc == \"\"):\n",
    "        xstrc = np.nan\n",
    "    return(xstrc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "par_csv = dict(index_col = 0, encoding = \"GB18030\", parse_dates = [\"ListingInfo\"], na_values = [-1], \n",
    "               converters = dict(zip(*[[\"UserInfo_{}\".format(i) for i in [9, 2, 4, 8, 20, 7, 19]], [Del_string]*7])))\n",
    "file_dat = [\"{}/{}_dat_{}.csv\".format(path, title, 1+x) for x in range(3)]\n",
    "file_dayt = [\"{}/{}_dayt_2_{}.csv\".format(path, title, x) for x in [1, 2]]\n",
    "file_dav = [\"{}/{}_dav.csv\".format(path, title)]\n",
    "dat = Read_concat_csv(file_dat, par_csv).fillna(Read_concat_csv(file_dayt, {\"index_col\": 0}))\n",
    "dav = Read_concat_csv(file_dav, par_csv)\n",
    "np.save(\"{}/{}_irt.npy\".format(path, title), list(dat.index))\n",
    "np.save(\"{}/{}_irv.npy\".format(path, title), list(dav.index))\n",
    "da = pd.concat([dat, dav])\n",
    "da.to_hdf(\"{}/{}_da.h5\".format(path, title), key = \"da\", complib = \"zlib\", complevel = 1, mode = \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Records Data\n",
    "Input:\n",
    "* LogInfo Data:\n",
    "    * PPD_daht_1_LogInfo.csv: First-round training set of LogInfo data\n",
    "    * PPD_daht_2_LogInfo.csv: First-round validation set of LogInfo data\n",
    "    * PPD_daht_3_LogInfo.csv: Second-round training set of LogInfo data\n",
    "    * PPD_dahv_LogInfo.csv: Second-round validation set of LogInfo data\n",
    "* UserupdateInfo Data:\n",
    "    * PPD_daht_1_Userupdate.csv: First-round training set of UserupdateInfo data\n",
    "    * PPD_daht_2_Userupdate.csv: First-round validation set of UserupdateInfo data\n",
    "    * PPD_daht_3_Userupdate.csv: Second-round training set of UserupdateInfo data\n",
    "    * PPD_dahv_LogInfo.csv: Second-round validation set of UserupdateInfo data\n",
    "    \n",
    "Output:\n",
    "* dah1: historical records data: LogInfo\n",
    "* dah2: historical records data: UserupdateInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Read_History(file, icid, ictime, par_csv = {}):\n",
    "    '''Organize Time-Dependent Historical Records\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file: a list of file name\n",
    "    icid: column name of id\n",
    "    ictime: a list of 2 column names: [basetime, recordtime]\n",
    "    par_csv: other parameters for pd.read_csv\n",
    "    '''\n",
    "    par = {\"parse_dates\": ictime}\n",
    "    par.update(par_csv)\n",
    "    dah = Read_concat_csv(file, par)\n",
    "    dahb = (dah.assign(Id = dah[icid], Time = (dah[ictime[1]] - dah[ictime[0]]).astype('timedelta64[D]')).set_index([\"Id\", \"Time\"])\n",
    "            .drop([icid]+ictime, axis = 1).sort_index())\n",
    "    return(dahb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "dah1 = Read_History(file = [\"{}/{}_dah{}_LogInfo.csv\".format(path, title, x) for x in [\"t_1\", \"t_2\", \"t_3\", \"v\"]],\n",
    "                      icid = 'Idx', ictime = ['Listinginfo1', 'LogInfo3'])\n",
    "dah2 = Read_History(file = [\"{}/{}_dah{}_Userupdate.csv\".format(path, title, x) for x in [\"t_1\", \"t_2\", \"t_3\", \"v\"]],\n",
    "                      icid = 'Idx', ictime = ['ListingInfo1', 'UserupdateInfo2'],\n",
    "             par_csv = {\"converters\": {\"UserupdateInfo1\": lambda x: x.lower()}})\n",
    "dah1.to_hdf(\"{}/{}_dah1.h5\".format(path, title), key = \"dah\", complib = \"zlib\", complevel = 1, mode = \"w\")\n",
    "dah2.to_hdf(\"{}/{}_dah2.h5\".format(path, title), key = \"dah\", complib = \"zlib\", complevel = 1, mode = \"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
